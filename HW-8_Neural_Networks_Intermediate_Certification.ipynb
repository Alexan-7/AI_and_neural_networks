{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-0P_Ul4aDhh","executionInfo":{"status":"ok","timestamp":1715846577076,"user_tz":-180,"elapsed":2204,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}},"outputId":"fd24b87e-b3b2-478e-821b-d6737f0a15ea"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"XCzOIo4Pjiuo"},"source":["# Введение в нейронные сети\n","## Задание по итогам курса:\n","Задание - Обучите нейронную сеть любой архитектуры на каком-то производственном датасете. Сделайте анализ того, что вам помогло в улучшения работы нейронной сети.\n","В конце, обязательно подвести вывод. Без этого минус балл.\n","\n","Датасет жестов взят отсюда:\n","https://www.kaggle.com/gti-upm/leapgestrecog\n","\n","Как работать с веб-камерой на google colab\n","https://stackoverflow.com/questions/54389727/opening-web-camera-in-google-colab\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ow8UwtM-VPri"},"source":["Ссылка на предобученные модели\n","https://huggingface.co/models\n","\n","https://huggingface.co/hustvl/yolos-tiny\n","\n","https://huggingface.co/hustvl/yolos-base"]},{"cell_type":"markdown","source":["# 1. Загрузка библиотек и данных для обучения модели распознавания жестов"],"metadata":{"id":"6AAwWNVI5w8v"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"ua5sX866faAt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715846595725,"user_tz":-180,"elapsed":18650,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}},"outputId":"5eb01fa9-0a85-4218-b78b-3effc55c8ae4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python==4.8.1.78 in /usr/local/lib/python3.10/dist-packages (4.8.1.78)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.8.1.78) (1.25.2)\n"]}],"source":["!pip install opencv-python==4.8.1.78"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"LRPWLpky6gq2","executionInfo":{"status":"ok","timestamp":1715846595725,"user_tz":-180,"elapsed":4,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["import os\n","import tqdm\n","import io\n","import html\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"WaaXI8ik6GnI","executionInfo":{"status":"ok","timestamp":1715846595725,"user_tz":-180,"elapsed":3,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["#модули для считывания изображений\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import PIL\n","import PIL.Image"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"OzbyxTmzg1F9","executionInfo":{"status":"ok","timestamp":1715846595725,"user_tz":-180,"elapsed":3,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","from keras import Model\n","from keras.applications.mobilenet import MobileNet, preprocess_input\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n","from keras.layers import Input, Dense, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, UpSampling2D, Reshape, GlobalAveragePooling2D\n","from keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import Adam\n","from keras.utils import Sequence, plot_model\n","from keras.backend import epsilon\n","from keras.losses import SparseCategoricalCrossentropy\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"XsDMr2AT5yX-","executionInfo":{"status":"ok","timestamp":1715846595725,"user_tz":-180,"elapsed":3,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["# модули для web-камеры\n","# from IPython.display import display, Javascript, Image\n","# from google.colab.output import eval_js\n","# from base64 import b64decode, b64encode\n","# from facenet_pytorch import MTCNN #Модуль для детектирования лица"]},{"cell_type":"markdown","source":["## 1.1. Импорт датасета жестов"],"metadata":{"id":"Oo4N2ygy_FZX"}},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"elapsed":263279,"status":"error","timestamp":1715846859001,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"},"user_tz":-180},"id":"Kj2aOExtkDuD","outputId":"79a568fb-68b6-4906-9de5-97a45ce2894f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c81b2df6-73dd-433d-aa4d-9f8696af9f34\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c81b2df6-73dd-433d-aa4d-9f8696af9f34\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-5e7cb60a130d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# импорт датасета жестов с kaggle\n","!pip install -q kaggle\n","from google.colab import files\n","files.upload()\n","\n","# from google.colab import drive\n","# drive.mount('/content/gdrive/', force_remount=True)\n","# !cp /content/gdrive/MyDrive/kaggle.json .\n","\n","!ls\n","!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets download -d gti-upm/leapgestrecog\n","\n","# path = '/content/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QjBcz9AdERvn","executionInfo":{"status":"aborted","timestamp":1715846859001,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["# !cp -r /content/gdrive/'My Drive'/'PyTorch'/'Photo_for_test' .\n","#скопировано фото для теста предобученной модели детекции объектов\n","# img1 = Image.open('/content/Photo_for_test/test1.jpeg')\n","#img2 = Image.open('/cotent/Photo_for_test/'+'2023-09-03 17-38-00.JPG')\n","# img3 = Image.open('/cotent/Photo_for_test/2023-08-19 20-43-09.JPG')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eixdRiIbkTC9","executionInfo":{"status":"aborted","timestamp":1715846859001,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["# #Распаковка загруженного датасета\n","# #!unzip leapgestrecog.zip\n","# ##Можно так:\n","# #import shutil\n","# #shutill.unpack_archive('leapgestrecog.zip', path, 'zip')\n","\n","# #А можно так:\n","from zipfile import ZipFile\n","with ZipFile('/content/leapgestrecog.zip', 'r') as zf:\n","    zf.extractall()\n","\n","#папки, где собраны фото жестов\n","!ls leapGestRecog/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2avfHrPkYwY","executionInfo":{"status":"aborted","timestamp":1715846859001,"user_tz":-180,"elapsed":6,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["from pathlib import Path\n","\n","DATA_ROOT = Path('/content/leapGestRecog/')"]},{"cell_type":"markdown","source":[" ## 1.2. Изучение входных данных"],"metadata":{"id":"e07UZ8FW6sL9"}},{"cell_type":"code","source":["#выведу список классов\n","from torchvision.datasets import ImageFolder\n","tmp_ds = ImageFolder(DATA_ROOT/'00')\n","CLASSES_NAMES = tmp_ds.classes\n","# CLASSES_NAMES.append('00_non_detected')\n","CLASSES_NAMES"],"metadata":{"id":"vAtKAEZIXyUc","executionInfo":{"status":"aborted","timestamp":1715846859001,"user_tz":-180,"elapsed":6,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJMFEhZ1mNv3","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["#оформление спиcка картинок в датафрейм\n","# gest_df = pd.DataFrame(make_df_from_files(), columns=('img', 'path', 'gest', 'person'))\n","# gest_df.head(5)\n","\n","import glob\n","img_filenames = glob.glob('/content/leapGestRecog/**/**/*.png') #извлекаем имена файлов\n","\n","# labels = [int(os.path.basename(i).split('_')[2])-1 for i in img_filenames] #извлекаем метки классов\n"]},{"cell_type":"code","source":["# всего в датасете 20000 картинок. Оперативка такой объем не тянет. Поэтому выберем из списка файлов 1000 штук рандомным образов\n","import random\n","img_filenames = random.sample(img_filenames, 1000)\n","labels = [int(os.path.basename(i).split('_')[2])-1 for i in img_filenames] #извлекаем метки классов"],"metadata":{"id":"P-A6OH7zgWSJ","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1715846859002,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"},"user_tz":-180},"id":"VHrDKdfQgmm6"},"outputs":[],"source":["print(img_filenames[0])\n","print(\"Размерность картинки:\", (PIL.Image.open(img_filenames[0])).size)\n","print(\"Цветовая кодировка картинки:\", PIL.Image.open(img_filenames[0]).mode)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1715846859002,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"},"user_tz":-180},"id":"_EZKQ1cGh5aw"},"outputs":[],"source":["print(set(labels))\n","print(type(labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAcxN0717ctX","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["# Функция отрисовки картинки из файлв\n","def show_image(images, labels, num_pictures, labels_to_compare=None):\n","    for ind, image in enumerate(images[:num_pictures]):\n","\n","        img = PIL.Image.open(image)\n","        plt.imshow(img)\n","        plt.title(f'Gest class: {CLASSES_NAMES[labels[ind]]}')\n","        if labels_to_compare != None:\n","            print(f'True label: {labels_to_compare[i]}')\n","        plt.show()\n","        # break"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1715846859002,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"},"user_tz":-180},"id":"pKMq7cFqEi0-"},"outputs":[],"source":["#посмотрим один из файлов\n","show_image(img_filenames, labels, 1)"]},{"cell_type":"markdown","source":["## 1.3. Преобразование входных данных для подачи в модель"],"metadata":{"id":"eCBIZwOoKksg"}},{"cell_type":"code","source":["IMAGE_SIZE = 224 #Именно такая рахмерность требуется на вход предобученной модели MobileNetV2"],"metadata":{"id":"oNG_ZTD8Kzpx","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import glob\n","# img_filenames = glob.glob('/content/*.jpg')\n","# img = PIL.Image.open(img_filenames[0])\n","# img.size\n","# # img = img.resize((256, 256))\n","# # img = np.asarray(img).flatten()\n","# # plt.imshow(img)"],"metadata":{"id":"HRlIWn0PaMcv","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# привожу каждое изображение к квадратному виду размерности 224*224 и цветовой шкале rgb\n","batch_images = np.zeros((len(img_filenames), IMAGE_SIZE, IMAGE_SIZE,3), dtype=np.float32)\n","\n","def prepare_image(image, size=IMAGE_SIZE, color_scale='RGB'):\n","    \"\"\" Принимает на вход считанную из файла картинку и приводит ее к заданному размеру, цветовой шкале и численному типу.\n","    На выходе получаем картинку в виде массива, который можно подать в модель \"\"\"\n","\n","    img = image.resize((size, size))\n","    img = img.convert(color_scale)\n","    img = preprocess_input(np.array(img, dtype=np.float32))\n","    return img\n","\n","for i, f in enumerate(img_filenames):\n","    img = PIL.Image.open(img_filenames[i])\n","    batch_images[i] = prepare_image(img)\n"],"metadata":{"id":"A0YtyMYlKx17","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_images.shape\n","#итого у нас батч их 1000 картинок размерностью 224*224 и 3 цветовыми каналами, приведен к типу np.float32"],"metadata":{"id":"MWUztu4HffV6","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":6,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# посмотрим, как теперь выглядит одна из картинок\n","plt.imshow(batch_images[10])\n","plt.title(f'Gest class: {CLASSES_NAMES[labels[10]]}')"],"metadata":{"id":"02nqIKNvY368","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":6,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#разбиваю на треин и тест\n","x_train, x_val, y_train, y_val = train_test_split(batch_images, labels, test_size=0.2, random_state=42)\n","y_train = np.array(y_train, dtype=np.float32)\n","y_val = np.array(y_val, dtype=np.float32)"],"metadata":{"id":"sjAdhrKrQgDL","executionInfo":{"status":"aborted","timestamp":1715846859002,"user_tz":-180,"elapsed":6,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Обучение модели распознавания жестов"],"metadata":{"id":"ObkKh6ry6awx"}},{"cell_type":"markdown","source":["## 2.2. Обучение модели"],"metadata":{"id":"O-WcGvdV61i7"}},{"cell_type":"code","source":["#использую предобученную нейросеть MobileNetV2\n","base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n","\n","# замораживаю слои базовой модели , чтобы не обучались\n","for layer in base_model.layers:\n","    layer.trainable = False\n","# добавляю самописные слои для обучения под задачу детекции жестов\n","x = GlobalAveragePooling2D(name=\"my_pooling_dence\")(base_model.output)\n","x = Dense(128, activation='relu', name=\"my_linear_dence\")(x)\n","y_preds = Dense(10, activation='softmax', name=\"my_clissifier_dence\")(x)\n","\n","# создаю модель\n","model = Model(inputs=base_model.input, outputs=y_preds)\n","plot_model(model, show_shapes=True)\n"],"metadata":{"id":"XVswBMsWIM8_","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9z4DaYN6Gc1E","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["model.compile(optimizer='adam',\n","                  loss=SparseCategoricalCrossentropy(),\n","                  metrics=['accuracy'])\n","\n","hist1 = model.fit(x_train, y_train,\n","                      epochs=10,\n","                      batch_size=200,\n","                      validation_data=(x_val, y_val))\n"]},{"cell_type":"code","source":["# Оценим модель на тестовых данных, используя \"evaluate\"\n","print('\\n# Оцениваем на тестовых данных')\n","results = model.evaluate(x_val, y_val)\n","print('test loss, test acc:', results)"],"metadata":{"id":"MMLzdJzMsArf","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Сгенерируем прогнозы (вероятности - выходные данные последнего слоя)\n","# на валидационных данных с помощью \"predict\"\n","print('\\n# Генерируем прогнозы для 3 образцов')\n","predictions = model.predict(x_val[:3])\n","print('размерность прогнозов:', predictions.shape)"],"metadata":{"id":"SxUEJN55vYsH","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#тестирую предсказание класса\n","dec = model.predict(x_val[10:11])\n","y_class = np.argmax(dec)\n","print('Предсказанные вероятности:', np.round(dec, 2))\n","print('Жест относится к классу:', y_class)"],"metadata":{"id":"BTrdBAjwyimc","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_val[10:11].shape"],"metadata":{"id":"PyVv_w9N63sk","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#функция детектирования жеста\n","def detect(img, model):\n","    \"\"\" На вход поступает картинка. Происходит предобработка и предсказание\n","    На выходе получаем класс объекта\"\"\"\n","    x = prepare_image(img)\n","    inp = np.expand_dims(x, axis=0)\n","    detect_probs = model.predict(inp[0:1])\n","    detected_class = np.argmax(detect_probs)\n","    return detected_class"],"metadata":{"id":"LzXia6po4kRT","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPvClw3CIVk4","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"outputs":[],"source":["#тестирую функцию детекции жестов\n","img = random.sample(img_filenames, 1)\n","img = PIL.Image.open(img[0])\n","y = detect(img, model)\n","print('Жест относится к классу:', y, CLASSES_NAMES[y])\n","plt.imshow(img)"]},{"cell_type":"code","source":["#сохранение модели распознавания жестов\n","model.save('/content/gest_recognition_tf_model.h5')"],"metadata":{"id":"ni9TX-gofmHj","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Детекция лица и жеста на реальных данных с веб-камеры"],"metadata":{"id":"-b3GOAH4-D_3"}},{"cell_type":"code","source":["#Тестирую модель на своих фото\n","import glob\n","img_filenames = glob.glob('/content/*.jpg')\n","img = PIL.Image.open(img_filenames[4])\n","# img = img.resize((256, 256))\n","# img = np.asarray(img).flatten()\n","plt.imshow(img)"],"metadata":{"id":"BVZV4vX2DWII","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = detect(img, model)\n","print('Жест относится к классу:', y, CLASSES_NAMES[y])"],"metadata":{"id":"aeHf35h-D7_f","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_loaded = tf.keras.models.load_model('/content/gest_recognition_tf_model.h5')\n","test_loss, test_acc = model_loaded.evaluate(x_val, y_val, verbose=2)"],"metadata":{"id":"eWI9ECywtYQV","executionInfo":{"status":"aborted","timestamp":1715846859003,"user_tz":-180,"elapsed":7,"user":{"displayName":"Александр Б.","userId":"00343257909382917122"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1NcvGRTXYjn5AkuPF5r63MXcw9CesHgTx","timestamp":1715844650361},{"file_id":"1g5PIdXXXDCpkq-PV3UQASJ-ME3DuBi1j","timestamp":1709562903920}],"gpuType":"T4","collapsed_sections":["eCBIZwOoKksg","ObkKh6ry6awx"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}